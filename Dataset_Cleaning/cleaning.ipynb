{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Feature Engineering of the Emory RCC Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to Take\n",
    "1. Load dataset into pandas dataframe\n",
    "1. Summarize info about dataset \n",
    "3. Parse dates \n",
    "4. Decouple compounded features\n",
    "5. Transform data\n",
    "6. Drop single value columns\n",
    "7. Clean dataframe dtypes\n",
    "8. Handle outliers\n",
    "9. Imputation\n",
    "10. Feature selection\n",
    "11. Sample dropping\n",
    "12. Scale and Normalize\n",
    "13. Clean col names\n",
    "14. Save cleaned CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: datetime.strptime(x, '%m/%d/%Y')\n",
    "df = pd.read_csv('../Data Sources/DO NOT MODIFY/US_RCC_Database.csv', skipinitialspace=True)\n",
    "df = df.infer_objects()\n",
    "# Drop all rows and columns that are completely empty\n",
    "empty_cols = [col for col in df.columns if df[col].isnull().all()]\n",
    "empty_rows = [row for row in df.index if df.iloc[row].isnull().all()]\n",
    "print(empty_cols)\n",
    "print(empty_rows)\n",
    "df.drop(labels=empty_cols, axis=1, inplace=True)\n",
    "df.drop(index=empty_rows, axis=0, inplace=True)\n",
    "data_shape = df.shape\n",
    "print(data_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having run a simple df.shape, this dataset has a total of 415 features and 1881 samples. That is a lot a features for the model to draw from, so we need to make sure they are all relevant to the task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few columns with duplicate names, we need to go through and adjust these to be more descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle cols with names that are identical, but end in a space\n",
    "df.rename(columns={'Sphincter Involvement ': 'Sphincter Involvement_Histopathology',\n",
    "                   'Intervention Required ': 'Intervention Required_Neoadjvant Complication'}, inplace=True)\n",
    "# NOTE: First result is 'Primary v. Recurrence', not relevant\n",
    "dup_cols = df.columns[df.columns.str.contains(\"\\.\")].to_list()[1:]\n",
    "new_names = ['Date of Initiation_NeoadjChemoRad',\n",
    "            'Date of Completion_NeoadjChemoRad',\n",
    "            'Number of Mesorectal Nodes by MRI_Post',\n",
    "            'Number of Mesorectal Nodes by ERUS_Post',\n",
    "            'Number of Retroperitoneal Nodes by CT_Post',\n",
    "            'Number of Retroperitoneal Nodes by MRI_Post',\n",
    "            'Number of Retroperitoneal Nodes by PET-CT_Post',\n",
    "            'Number of Pelvic Nodes on CT_Post',\n",
    "            'Number of Pelvic Nodes on MRI_Post',\n",
    "            'Number of Pelvic Nodes on PET-CT_Post',\n",
    "            'Involvement of Pelvic Sidewall_Post',\n",
    "            'Distal Circumferential or Radial Margin (mm)_Post',\n",
    "            'Sphincter Involvement_Post',\n",
    "            'Invasion into Reproductive Organs_Post',\n",
    "            'Invasion into Bladder_Post',\n",
    "            'Invasion into Sacrum_Post',\n",
    "            'Invasion of Sacral Nerve Roots_Post',\n",
    "            'Involvement of Pelvic Sidewall_Op',\n",
    "            'Omental Flap to Pelvis_Op_APR',\n",
    "            'T-Stage_Recurrence',\n",
    "            'N-Stage_Recurrence',\n",
    "            'Type of Operation of Rectal Tumor_Recurrence',\n",
    "            'Distal Margin Distance (cm)_Recurrence',\n",
    "            'Radial Margin Distance (mm)_Recurrence',\n",
    "            'Date of Diagnosis_PostOp_Leak',\n",
    "            'Acute Renal Failure_PostOp',\n",
    "            'Date of Discharge_Readmission',\n",
    "            'Date of Initiation_AdjChemo',\n",
    "            'Date of Completion_AdjChemo',\n",
    "            'Date of Initiation_AdjChemoRad',\n",
    "            'Date of Completion_AdjChemoRad',\n",
    "            'Radiation Technique_AdjChemoRad',\n",
    "            'Date of Initiation_AdjRad',\n",
    "            'Date of Completion_AdjRad',\n",
    "            'Sacrum_Recurrence_Locoregional',\n",
    "            'Bladder_Recurrence_Locoregional',\n",
    "            'Seminal Vesicles_Recurrence_Locoregional',\n",
    "            'Prostate_Recurrence_Locoregional',\n",
    "            'Vagina_Recurrence_Locoregional',\n",
    "            'Ureter_Recurrence_Locoregional',\n",
    "            'Grey (Gy)_Recurrence_Rad',\n",
    "            'Ablation_Recurrence']\n",
    "\n",
    "df.rename(columns=dict(zip(dup_cols, new_names)), inplace=True)\n",
    "# Remove whitespace from names\n",
    "df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "# Strip whitespace from all string values\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].str.strip()\n",
    "assert df.shape == data_shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarize information about dataset\n",
    "First, to aid in the cleaning process, we'll extract the number of missing and unique (if discrete) values for each feature and save to a file for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.violinplot(y=df.isnull().sum(), orient=\"v\", width=0.5)\n",
    "plot.set_title(\"Missing Values per Column\")\n",
    "plt.show()\n",
    "plot = sns.violinplot(y=[len(df[col].unique()) for col in df.select_dtypes(include=['object']).columns if \"Date\" not in col and col != \"Database ID\"], orient=\"v\", width=0.5)\n",
    "plot.set_title(\"Unique Values per Categorical Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.DataFrame({\"Name\": df.columns.to_list(),\n",
    "                          \"dtype\": df.dtypes.to_list(),\n",
    "                          \"Num Non-Null\": df.count(axis=0).to_list(),\n",
    "                          \"Num Unique\": [len(df[col].unique()) for col in df.columns]})\n",
    "data_info.to_csv(\"../Data Documentation/data_info.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Drop unimportant columns\n",
    "These are columns that either provide unimportant information or have less than 10 non-null samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Complication after Stenting', 'Radiotherapy Complications', 'Intervention for Peritoneal Perforation', 'Radiation Technique_AdjChemoRad', 'Reason for Rectal Stent', 'Date of Completion_AdjRad', 'Grey (Gy)', 'Date of Initiation_AdjRad', 'Ovary']\n",
    "df = df.drop(columns=drop_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning treatments and complications\n",
    "Each column to be binned has its own dict with the keys being the bins to place the values and the items being an array of unique values that belong in that bin. Chemotherapies will be one hot encoded and given additional features: how many times the therapy was changed, if the cocktail had to be reduced, and what the second therapy was (if applicable). Only the second therapy will be noted because only a handful of samples had more than two therapies. Complications will be one-hot encoded as well, but weighted based on the grade of the complication and the number of other complications of the same nature. All other features will have their unique values concatenated into their respective bin so the model can draw inferences between the magnitude of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tokens(col_name: str, split_indicators: list, df: pd.DataFrame):\n",
    "    values = df[col_name]\n",
    "    null_values = values.isnull()\n",
    "    enumerator = 0\n",
    "    unique_tokens = []\n",
    "    for value in values:\n",
    "        if null_values.get(enumerator) == False:\n",
    "            for indicator in split_indicators:\n",
    "                value = value.replace(indicator, ',')\n",
    "            tokens = value.split(',')\n",
    "            trigger = False\n",
    "            for token in tokens:\n",
    "                token = token.strip().lower()\n",
    "                for u in unique_tokens:\n",
    "                    if token == u.lower():\n",
    "                        trigger = True\n",
    "                if (not trigger):\n",
    "                    unique_tokens.append(token)\n",
    "                trigger = False\n",
    "        enumerator += 1\n",
    "    return unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin(col_name: str, bin_dict: dict, df: pd.DataFrame, one_hot = False):\n",
    "    \"\"\"Bins feature according to provided dict, retaining the magnitude and severity of occurrences, \n",
    "    splitting into separate cols for each key. The contents of each new col is the frequency of the \n",
    "    key values in the original data. If a grade is present, the item value increases by the grade number.\n",
    "    If the one_hot flag is true, values are clipped to 1 and cast to bool.\"\"\"\n",
    "    # TODO: Handle data that does not fall under a binning key?\n",
    "    col_data = df[col_name]\n",
    "    null_entries = col_data.isnull()\n",
    "    col_index = df.columns.get_loc(col_name)\n",
    "    key_num = 0\n",
    "    for key in bin_dict:\n",
    "        new_values = []\n",
    "        items = bin_dict[key]\n",
    "        iterator = 0\n",
    "        for data in col_data:\n",
    "            new_values.append(0)\n",
    "            if null_entries.get(iterator) == False:\n",
    "                for item in items:\n",
    "                    item_index = data.lower().find(item)\n",
    "                    if item_index != -1:\n",
    "                        severity = 1\n",
    "                        # Handle scaling by grade, if present\n",
    "                        if 'grade' in data.lower():\n",
    "                            # Check 'grade' is between the commas bounding the found item\n",
    "                            grade_index = -1\n",
    "                            end_comma = data.lower().find(',', item_index)\n",
    "                            lead_comma = data.lower().rfind(',', 0, end_comma)\n",
    "                            if end_comma != -1 and lead_comma != -1:\n",
    "                                grade_index = data.lower().find('grade', lead_comma, end_comma)\n",
    "                            elif end_comma == -1 and lead_comma != -1:\n",
    "                                grade_index = data.lower().find('grade', lead_comma)\n",
    "                            elif end_comma != -1 and lead_comma == -1:\n",
    "                                grade_index = data.lower().find('grade', 0, end_comma)\n",
    "                            else: \n",
    "                                grade_index = data.lower().find('grade')\n",
    "                            if grade_index != -1:\n",
    "                                grade_val_ind = grade_index + 6\n",
    "                                grade_val = 0\n",
    "                                # Handle roman numeral (singe edge case w/ 'III')\n",
    "                                if data[grade_val_ind] == 'I':\n",
    "                                    while data[grade_val_ind] == 'I':\n",
    "                                        grade_val += 1\n",
    "                                        grade_val_ind += 1\n",
    "                                else: grade_val = int(data[grade_val_ind])\n",
    "                                severity = grade_val\n",
    "                        new_values[iterator] += severity\n",
    "\n",
    "            # if original value NA, make new val NA as well\n",
    "            else:\n",
    "                new_values[iterator] = pd.NA\n",
    "            iterator += 1\n",
    "        new_col_name = col_name + '_' + key\n",
    "        df.insert(col_index, new_col_name, new_values, allow_duplicates = False)\n",
    "        # Make copy to avert performance warning due to fragmentation\n",
    "        df = df.copy(deep=True)\n",
    "        if one_hot:\n",
    "            df[new_col_name] = df[new_col_name].clip(upper=1)\n",
    "            df[new_col_name] = df[new_col_name].astype('boolean')\n",
    "        else: \n",
    "            df[new_col_name] = pd.to_numeric(df[new_col_name])\n",
    "        key_num += 1\n",
    "    df = df.drop(columns = col_name)\n",
    "    # Make copy to avert performance warning due to fragmentation\n",
    "    df = df.copy(deep=True)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Therapy Complications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Some conditions and symptoms will be counted twice, there are a few reasons for this:\n",
    "# * They belong to two classes at once Ex) 'perianal skin'\n",
    "# * They are specific in nature, but also cause general pain Ex) 'thrombophlebitis'\n",
    "# * They are confounded, which increases their severity Ex) 'rectal pain and bleeding'\n",
    "complication_dict = {\n",
    "    'Cardiovascular': ['nstemi', 'coronary vasospasm', 'vascular spasm of the fingers', 'thrombophlebitis', 'dvt', 'atrial fibrillation'],\n",
    "    'Blood/Bone Marrow': ['thrombocytopenia', 'low platelets', 'induced thromboctopenia', 'anemia', 'low wbc', 'neutropenia', 'sepsis', 'cytopenia', 'necrosis', 'bacteremia'],\n",
    "    'Constitutioinal Symptoms': ['nose and lip bleeding', 'suicidal ideations', 'anorexia', 'sirs', 'dehydration', 'failure to thrive', 'fatigue', 'cold intolerance', 'night sweats', 'cold sensitivity', 'hair loss', 'dizziness', 'nausea', 'vomitting', 'tongue and throat sensitivity', 'alopecia', 'allergic reaction', 'abdominal cramping'],\n",
    "    'Dermatology': ['periananl skin', 'rash', 'hand foot syndrome', 'gout flare', 'hand and foot', 'palmar-plantarerythrodysesthesia', 'dermatitis', 'cellulitis', 'pruritis', 'skin toxicity', 'skin erythema', 'desquamation', 'skin reaction', 'skin irrritation', 'perineal and vaginal skin irritation', 'skin changes', 'pruritus', 'hand-foot syndrome', 'skin issues', 'abscess'],\n",
    "    'Reproductive': ['genital herpes', 'erectile dysfunction', 'menorrhagia', 'vagina'], \n",
    "    'Pulmonary': ['pneumothorax', 'pe', 'pulmonary hypertension', 'tracheal bronchitis', 'pneumonia'], \n",
    "    'Renal': ['ureter obstruction', 'acute kidney injury', 'aki', 'urinary', 'uti', 'incontinence', 'dysuria'],\n",
    "    'Pain': ['low backache', 'pain', 'perirectal burning', 'thrombophlebitis', 'gout', 'cramping', 'dysuria', 'sores', 'ulcers', 'hernia', 'abscess'],\n",
    "    'Neurology': ['numb', 'neuropathy', 'taste alteration', 'chemo brain'], \n",
    "    'Gastrointestinal': ['diarrhea', 'constipation', 'esophageal spasm', 'fecal obstruction', 'gi', 'colitis', 'bowel obstruction', 'sbo', 'dysphagia', 'mucositis', 'crohn', 'pyroderma gangrenosum', 'hernia', 'ileitis', 'enteritis', 'pneumatosis', 'diverticulitis', 'mucousitis', 'stomatitis'],\n",
    "    'Rectum': ['proctitis', 'rectal', 'anal', 'periananl', 'perineal', 'fistula', 'inguinal', 'rectal pain and bleeding', 'hemorrhoids', 'prostatitis']\n",
    "}\n",
    "\n",
    "df = bin('Complication During Neoadjuvant Treatment', complication_dict, df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Operative Complications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operative_dict = {\n",
    "    'GI Mesenteric Vessel Injury': ['mesenteric injury', 'colonic ischemia requiring excision of colon to hepatic flexure', 'ischemia noted without obvious vascular injury/disruption. distal transverse and descending colon were resected along with appendectomy', 'colorectal anastomosis', 'ischemia to colon requiring deloters procedure'],\n",
    "    'GI Rectal Injury': ['bladder injury - Urinary tract hole in rectal stump after firing stapler', 'tear in rectum distal to anastomosis', 'entered the vagina and the rectal lumen accidentally', 'rectal injury', 'proctotomy'],\n",
    "    'GI Anastomotic Leak': ['anastamotic defect', 'anastomotic leak requiring dli', 'staples did not hold rectal stump closed', 'anatosmotic leak repaired', 'positive leak test'],\n",
    "    'Vaginal Injury': ['vaginal injury', 'hole created in posterior vaginal wall', 'entered the vagina and the rectal lumen accidentally', 'colpotomy'],\n",
    "    'GI Small Bowel Injury': ['small bowel cautery injury', 'bowel injury', 'small bowel enterotomy'],\n",
    "    'Prostate Injury': ['tear in rectum distal to anastomosis'],\n",
    "    'Bleeding-Operative': ['bleeding', 'acidosis'],\n",
    "    'Urinary Tract Injury': ['bladder injury', 'ureteral injury', 'coagulopathy', 'urethral injury'],\n",
    "    'Spleen Injury': ['splenic capsule tear']\n",
    "}\n",
    "df = bin('Type of Intraoperative Complication', operative_dict, df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Organs Invaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ_dict = {\n",
    "    'Reproductive-Invaded': ['vagina', 'vas deferens', 'cervix', 'prostate', 'seminal vesticles', 'uterus', 'fallopian tube', 'ovaries', 'scrotum', 'ovary'],\n",
    "    'Colon': ['colon'],\n",
    "    'Anus': ['anus', 'peri-anal skin with metastatic lesion'],\n",
    "    'Urinary Tract': ['urinary', 'periureteral soft tissue', 'bladdder', 'ureter', 'bladder'],\n",
    "    'Nodes': ['nodes'],\n",
    "    'Sacrum-Invaded': ['pre-sacral tissue', 'sacrum'],\n",
    "    'Liver-Invaded': ['liver'],\n",
    "    'Pelvic Bone': ['pelvic wall', 'obturator side wall', 'coccyx', 'pelvis', 'pelvic side wall', 'perisacral soft tissue'],\n",
    "    'Pelvic Floor': ['pelvic floor muscle'],\n",
    "    'Omentum': ['omentum'],\n",
    "    'Spleen': ['spleen'],\n",
    "    'Peritoneum': ['peritoneum'],\n",
    "    'Soft Tissue': ['ab wall', 'buttocks'],\n",
    "    'Small Bowel-Invaded': ['small bowel', 'ileum'],\n",
    "    'Stomach': ['stomach'],\n",
    "    'Mesentery': ['mesentary', 'mesentery'],\n",
    "    'Vessels': ['iliac vessels']\n",
    "}\n",
    "\n",
    "df = bin('Organs Invaded', organ_dict, df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diagnosis at Readmission\n",
    "\n",
    "The column 'Diagnosis at Readmission' has 146 unique values for only 403 non-null samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmission_dict = {\n",
    "    'Cardiovascular': ['nstemi', 'dvt', 'fibrillation', 'heart failure', 'arrhythmia', 'cva', 'tachycardia', 'myocardial infarction', 'arrest', 'cardiomyopathy', 'svt'],\n",
    "    'Blood': ['bleed', 'hematoma', 'pe', 'pulmonary embolus', 'hematuria', 'portal vein thrombosis', 'dvt', 'anemia', 'sepsis', 'bacteremia', 'dka', 'supratherapeutic inr'],\n",
    "    'Constitutional Symptoms': ['dehydration', 'failure to thrive', 'fatigue', 'dizziness', 'nausea',  'syncope', 'confusion', 'anxiety', 'deconditioning', 'weakness'],\n",
    "    'Pelvic/Vaginal': ['vagina', 'pelvic', 'perineal', 'presacral', 'retroperitneal'], \n",
    "    'Pulmonary': ['pe', 'pneumonia', 'respiratory', 'pulmonary embolus', 'lung', 'pleural effusion', 'pneumomediastinum', 'dyspnea'], \n",
    "    'Renal': ['acute kidney injury', 'aki', 'urinary', 'uti', 'incontinence', 'dysuria', 'hematuria', 'pyelonephritis', 'urosepsis', 'renal', 'uropathy', 'hydronephrosis', 'biliary obstruction'],\n",
    "    'Pain': ['pain', 'dysuria', 'abscess', 'hernia'],\n",
    "    'Gastrointestinal': ['diarrhea', 'constipation', 'gi', 'bowel obstruction', 'enteritis', 'c. diff', 'liver', 'melena', 'peritoneal', 'ileus', 'gastritis', 'obstipation', 'abdominal', 'hepatic', 'obstruction from food bolus', 'anastomosis', 'anastomotic', 'anastamoses', 'internal hernia', 'colo', 'peritonitis'],\n",
    "    'Rectum': ['rectal', 'anal', 'recto'],\n",
    "\t'Operative': ['hematoma', 'ostomy', 'parastomal', 'periostomal', 'ostomy appliance dysfunction', 'lapro right hemicolectomy', 'complication', 'leak', 'anastamoses', 'stricture', 'dehiscence', 'surgical', 'ssi', 'malfunctioning foley', 'anastomosis', 'nonhealing perineal wound', 'fistula', 'bleeding from perineal wound'],\n",
    "\t'Cancer-related': ['carcinoma', 'metastasis', 'metastisis', 'mets', 'mass', 'cancer', 'recurrence', 'nodules', 'chemotherapy'],\n",
    "\t'Illness/Infection': ['infection', 'pneumonia', 'uti', 'sepsis', 'bacteremia', 'fever', 'pyelonephritis', 'ssi', 'flu'],\n",
    "\t'Misc': ['neurosurgery consult', 'no surgical intervention', 'fall', 'unknown', 'skin excoriation', 'dysphasia', 'nerve'],\n",
    "}\n",
    "\n",
    "df = bin('Diagnosis at Readmission', readmission_dict, df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chemo Regimens\n",
    "Make a seperate feature that indicates if a patient had to switch regimens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_chemo(col_name: str, bin_dict: dict, df: pd.DataFrame):\n",
    "    \"\"\"Bins chemo regimen column according to provided dictionary. Adds features for \n",
    "    the # of changes to the regimen, if the regimen needed to be reduced, and any secondary regiments\"\"\"\n",
    "    col_data = df[col_name]\n",
    "    chemo_reduced = []\n",
    "    chemo_changed = []\n",
    "    chemo_initial = []\n",
    "    chemo_secondary = []\n",
    "    for sample in col_data:\n",
    "        if not pd.isnull(sample):\n",
    "            sample = sample.lower()\n",
    "            # Count times reg. reduced by the frequency of 'reduce', '%', or 'discontinue'\n",
    "            # NOTE: one known edge case where 'reduce' and '%' are redundant (DID: UM061)\n",
    "            chemo_reduced.append(sum(sample.count(indicator) for indicator in [\"reduce\", \"%\", \"discontinue\"]))\n",
    "            # Count the number of changes by the frequency of ',', '>', or ';'\n",
    "            change_indicators = [\",\", \">\", \";\"]\n",
    "            chemo_changed.append(sum(sample.count(indicator) for indicator in change_indicators))\n",
    "            # Split string on first change\n",
    "            if chemo_changed[-1] > 0:\n",
    "                for indicator in change_indicators:\n",
    "                    change_ind = sample.find(indicator)\n",
    "                    if change_ind > 0:\n",
    "                        chemo_initial.append(sample[:change_ind])\n",
    "                        secondary = sample[change_ind:]\n",
    "                        # If a therapy was added to the initial (only one edge case)\n",
    "                        if secondary.find(\"add\", 10) != -1: secondary = sample\n",
    "                        chemo_secondary.append(secondary)\n",
    "                        break\n",
    "            else: \n",
    "                chemo_initial.append(sample)\n",
    "                chemo_secondary.append('None')\n",
    "        else:\n",
    "            chemo_reduced.append(pd.NA)\n",
    "            chemo_changed.append(pd.NA)\n",
    "            chemo_initial.append(pd.NA)\n",
    "            chemo_secondary.append(pd.NA)\n",
    "\n",
    "    df.insert(df.columns.get_loc(col_name), col_name + \"_Secondary\", chemo_secondary, allow_duplicates = False)\n",
    "    df.insert(df.columns.get_loc(col_name), col_name + \"_Initial\", chemo_initial, allow_duplicates = False)\n",
    "    df.insert(df.columns.get_loc(col_name), col_name + \"_Changes\", chemo_changed, allow_duplicates = False)\n",
    "    df.insert(df.columns.get_loc(col_name), col_name + \"_Reductions\", chemo_reduced, allow_duplicates = False)\n",
    "    df = df.drop(columns = col_name)\n",
    "\n",
    "    df = bin(col_name + \"_Initial\", bin_dict, df, True)\n",
    "    df = bin(col_name + \"_Secondary\", bin_dict, df, True)    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemo_dict = {\n",
    "    'Folfox': ['xelox', 'folfox', 'oxaliplatin', 'flox', 'capox', 'folfirinox', 'capeox', 'xeliri', 'foflox', 'xeleri'],\n",
    "    '5FU': ['xeloda', 'capecitabine', '5-fu', 'leucovorin', '5fu', 'leocovorin', 'leukovorin', 'cabecitabine'],\n",
    "    'Biologic': ['avastin', 'bbi', 'panitumumab', 'pembro', 'nivolumab', 'erbutux', 'cetuximab', 'erbitux', 'bev', 'cituximab', 'vectibix', 'xl888 trial', 'panitumaumab', 'lonsurf', 'ipilimumab', 'avastn', 'cetuximab', 'avastatin', 'avasrin'],\n",
    "    'Folfiri': ['irinotecan', 'folfiri', 'capiri', 'bi5013', 'folriri'],\n",
    "    'Interleukin': ['nktr-214 (pegylated il-2)'],\n",
    "    'Alt Chemo': ['etoposide', 'camtosar', 'cisplatin', 'carboplatin', 'carboxyplatin', 'mmc', 'other']\n",
    "}\n",
    "\n",
    "regimen_cols = ['Neoadjuvant Chemo Regimen', 'Adjuvant Chemo Regimen', 'Chemotherapy Regimen']\n",
    "for col in regimen_cols:\n",
    "    df = bin_chemo(col, chemo_dict, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Chemotherapy Regimen_Reductions', non-na values are all 0\n",
    "df = df.drop(columns='Chemotherapy Regimen_Reductions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most values in 'Distal Circumferential or Radial Margin (mm)' and 'Distal Circumferential or Radial Margin (mm)_Post' are either '>0' or '0', so we'll bin along these lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all '> 0' values to 1's for binning\n",
    "df['Distal Circumferential or Radial Margin (mm)'].replace(to_replace=\"> 0\", value=1, inplace=True)\n",
    "df['Distal Circumferential or Radial Margin (mm)'] = pd.to_numeric(df['Distal Circumferential or Radial Margin (mm)'])\n",
    "df['Distal Circumferential or Radial Margin (mm)_Post'].replace(to_replace=\"> 0\", value=1, inplace=True)\n",
    "df['Distal Circumferential or Radial Margin (mm)_Post'] = pd.to_numeric(df['Distal Circumferential or Radial Margin (mm)_Post'])\n",
    "\n",
    "# Bin using pd.cut\n",
    "df['Distal Circumferential or Radial Margin (mm)'] = pd.cut(df['Distal Circumferential or Radial Margin (mm)'], [-1000000000, 0, 1000000000], labels = ['0', '>0'])\n",
    "df['Distal Circumferential or Radial Margin (mm)_Post'] = pd.cut(df['Distal Circumferential or Radial Margin (mm)_Post'], [-1000000000, 0, 1000000000], labels = ['0', '>0'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode possible values for 'Location of Metastatic Disease', 'Prior Abdominal Operation', 'Radiation Dose', 'CURRENT Tumor Category', 'Region of Recurrence'. This is a lot simpler, common tokens and separated by ' + '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metastatic_dict = {\n",
    "    'Peritoneum': ['peritoneum'],\n",
    "    'Lung': ['lung'],\n",
    "    'Liver': ['liver'],\n",
    "    'Other': ['other'],\n",
    "}\n",
    "\n",
    "df = bin('Location of Metastatic Disease', metastatic_dict, df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_ab_op_dict = {\n",
    "    'Open': ['open'],\n",
    "    'Laparoscopic': ['laparoscopic']\n",
    "}\n",
    "\n",
    "df = bin('Prior Abdominal Operations', prior_ab_op_dict, df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_dose_dict = {\n",
    "    'Standard': ['standard'],\n",
    "    'Boost': ['boost']\n",
    "}\n",
    "\n",
    "df = bin('Radiation Dose', rad_dose_dict, df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_cat_dict = {\n",
    "    'Primary Rectal Tumor': ['primary rectal'],\n",
    "    'Recurrent Rectal Tumor': ['recurrent rectal'],\n",
    "    'Synchronous Liver Metastases': ['liver metastases'],\n",
    "}\n",
    "\n",
    "df = bin('CURRENT Tumor Category', tumor_cat_dict, df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = {\n",
    "    'Local': ['local'],\n",
    "    'Regional': ['regional'],\n",
    "    'Distant': ['distant'],\n",
    "}\n",
    "\n",
    "df = bin('Region of Recurrence', region_dict, df, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Gather miscellaneous values\n",
    "\n",
    "Consider:\n",
    "- Change all non-na values to 'Yes' and na values to 'No' for 'Previous Diagnosis of Cancer'\n",
    "- Any possible binning for 'Method of Metastatic Tumor Biopsy', 'Method of Metastatic Tumor Biopsy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change any 'Data Unavailable' values to be null\n",
    "# Change any 'Not applicable' or 'Not applicablet applicable' values to be null for 'Indication for Palliative Resection', 'Operative Approach', 'Reason for Conversion to Open', 'Method of Metastatic Tumor Biopsy', 'Mobilization of Splenic Flexure', 'Ulcerative Colitis', 'Crohn's Disease', 'Method of Anastomosis', 'Additional Pelvic Nodes Resected', 'Sacrum', 'Final Proximal Margin Status', 'Final Distal Margin Status', 'Final Radial Margin Status', 'Tumor Budding', 'Necrosis', 'Mucinous', 'KRAS Status', 'BRAF Status', 'APC Status', 'P53 Status', 'MLH1 Status', 'MSH2 Status', 'MSH6 Status', 'PMS2 Status', 'Method of Total Mesorectal Excision', 'Repair of Perineal Hernia', 'Indication for Reoperation', 'Surveillance by EUS'\n",
    "# Change any 'No reason stated' values to be null for 'Reason for Conversion to Open'\n",
    "# Group 'Child Class A' and 'Child Class B' together as 'Yes' for 'Chronic Liver Disease'\n",
    "# Group all values containing 'incontinence' together in col 'Pre-Treatment Bladder Dysfunction', 'Bladder Dysfunction'\n",
    "# Make all non-na values 'Yes' for 'Pre-Treatment Sexual Dysfunction', 'Pre-Treatment Fecal Incontinence', 'Bowel Obstruction', 'Malignant Fistula', 'Ulcerative Colitis', 'Crohn's Disease', 'Additional Pelvic Nodes Resected', 'Sacrum', 'Sexual Dysfunction', 'Fecal Incontinence', 'Repair of Perineal Hernia'\n",
    "# Make all non 'No' values 'Yes' for 'Diverting Ostomy Before Surgery', 'Ureteral Obstruction', 'Pelvic Exenteration'\n",
    "# Make all 'yes' values 'Yes' for 'Neoadjuvant Chemo Treatment Completed'\n",
    "# Make all 'External Beam' values 'External beam' for 'Radiation Technique'\n",
    "# Changed 0 to 'No' and 1 to 'Yes' in 'Portion of Sphincters Resected', 'Defect Closure', 'Peritoneal Perforation', 'Positive Margin Requiring Re-excision', 'Need for Radical Resection', 'Intervention Required', 'Ostomy Reversed after Resolution of Leak', 'Radiation' \n",
    "# Change all values containing 'adenocarcinoma' to 'Adenocarcinoma' and all other non-na 'Other' for 'Histopathologic Type'\n",
    "# Change all 'Cannot be assessed' values to null for 'Tumor Differentiation', 'Final Proximal Margin Status',  'Final Distal Margin Status', 'Final Radial Margin Status', \n",
    "# Change all 'Not assessed' values to be null for 'Lymphovascular Invasion (LVI)', 'Perineural Invasion (PNI)', 'KRAS Status', 'BRAF Status', 'APC Status', 'P53 Status', 'MLH1 Status', 'MSH2 Status', 'MSH6 Status', 'PMS2 Status'\n",
    "# Make any values containing 'negative' equal 'Negative for carcinoma' and 'positive' equal 'Positive for carcinoma' for 'Final Proximal Margin Status', 'Final Distal Margin Status', 'Final Radial Margin Status'\n",
    "# Make all non-na, non 'Dysplasia' values equal 'Other' for 'Additional Pathologic Findings'\n",
    "# Make any values containing 'rehab' equal 'Rehab' for 'Discharge Destination'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use panda's built-in to_datetime() to parse dates. \n",
    "\n",
    "**Note**: We found several samples without a year in 'Date of Diagnosis'. We opted to drop these for now, but if necessary it may be possible to impute the year from 'Date of First Oncologic Consultation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop bad samples\n",
    "df = df.drop(df[df['Date of Diagnosis'].str.contains(\"-\", regex=False, na=False)].index)\n",
    "\n",
    "date_cols = df.columns[df.columns.str.contains(\"Date\")].to_list()\n",
    "for date_col in date_cols:\n",
    "    df[date_col] = pd.to_datetime(df[date_col], dayfirst=True, format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_invalid_samples(invalid: list, col_name: str, df: pd.DataFrame):\n",
    "    drop_inds = df[df[col_name].str.contains('|'.join(invalid), na=False)].index\n",
    "    print(\"Dropping {} samples containing one of {} from column {}\".format(len(drop_inds), invalid, col_name))\n",
    "    return df.drop(drop_inds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the units for duration columns to all be in weeks. Values in months can be converted, but values in 'cycles' cannot and will be dropped\n",
    "* Adjuvant Chemo Duration: weeks\n",
    "* Duration of Neoadjuvant Chemo (months): months\n",
    "* Duration of Neoadjuvant ChemoXRT (in months): months\n",
    "\n",
    "Excluding:\n",
    "- 'Return of Bowel Function': units in days\n",
    "- 'Time to Drain Removal (days)': units in days\n",
    "- 'Time to Ileostomy Reversal (days)': units in days\n",
    "- 'LOS (days)': units in days\n",
    "- 'LOS Readmission': units likely in days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_cols = ['Adjuvant Chemo Duration', 'Duration of Neoadjuvant Chemo (months)', 'Duration of Neoadjuvant ChemoXRT (in months)']\n",
    "\n",
    "for col in duration_cols: \n",
    "    df = drop_invalid_samples(['cycles'], col, df)\n",
    "    for index in range(len(df[col])):\n",
    "        if pd.isnull(df[col].values[index]): continue\n",
    "        sample = str(df[col].values[index]).lower()\n",
    "        # NOTE: With 'cycles' removed, the samples in these cols can only have the suffix 'months'\n",
    "        if 'months' in col or 'months' in sample:\n",
    "            sample = int(sample.strip(' months'))\n",
    "            sample *= 4\n",
    "            df[col].values[index] = str(sample)\n",
    "    df[col] = pd.to_numeric(df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column 'Distance from Sphincters' was misclassified as an Object but contains only floats, will have to cast it manually..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Distance from Sphincters'] = pd.to_numeric(df['Distance from Sphincters'], errors = 'coerce')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Several features that should be numeric are being interpreted as strings or objects because of some values that contain ranges. We need to either drop these values, bin them, or impute with the mean of their interval\n",
    "- CEA (ng/mL)\n",
    "- CEA Level (ng/mL) at Recurrence\n",
    "- Radial margin should be grouped into >=3 \n",
    "- Distal margin should be grouped into >=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_invalid_samples([\"<\", \">\", \"-\"], 'CEA (ng/mL)', df)\n",
    "df['CEA (ng/mL)'] = pd.to_numeric(df['CEA (ng/mL)'])\n",
    "\n",
    "df = drop_invalid_samples([\"<\", \">\", \"-\"], 'Distal Circumferential or Radial Margin (mm)', df)\n",
    "df['Distal Circumferential or Radial Margin (mm)'] = pd.to_numeric(df['Distal Circumferential or Radial Margin (mm)'])\n",
    "\n",
    "df = drop_invalid_samples([\"<\", \">\", \"-\"], 'Distal Circumferential or Radial Margin (mm)_Post', df)\n",
    "df['Distal Circumferential or Radial Margin (mm)_Post'] = pd.to_numeric(df['Distal Circumferential or Radial Margin (mm)_Post'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Some features are objects but can be represented as hierarchial numeric features. We need to parse these. *Note: All 'Data Unavailable' values should be na by this point*\n",
    "- 'Clinical Response after Neoadjuvant Treatment': {1: 'cNon', 2: 'pCR', 3: 'cCR'}\n",
    "- 'Wound Class': Cut 'Class' and convert roman numerals to ints\n",
    "- Cancer stage features (incl 'TNM Grade' and 'Depth of Invasion'): Place in hierarchy according to [ACS guidelines](https://www.cancer.org/cancer/types/colon-rectal-cancer/detection-diagnosis-staging/staged.html)\n",
    "- 'Tumor Differentiation': According to [tumor grade](https://www.cancer.gov/about-cancer/diagnosis-staging/diagnosis/tumor-grade)\n",
    "- 'Final Primary Rectal Tumor Resection Status', 'Final LIVER Resection Status': Cut 'R' and cast to int\n",
    "- 'Pathologic Response': {1: 'No response', 2: 'Partial response', 3: 'Complete response'}\n",
    "- 'Completeness of TME': {1: 'Incomplete', 2: 'Near Complete', 3: 'Complete'}\n",
    "- 'Minor vs Major Complication': {1: 'No complication', 2: 'Minor complication', 3: 'Major complication'}\n",
    "- 'Highest Clavien-Dindo Grade': According to Fig 1 [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1360123/)\n",
    "- 'Time to Readmission', 'Time to Death': Start with 1 for '≤30 days', end with 4 for '>90 days'\n",
    "- 'Locoregional Surveillance Frequency', 'Distant Surveillance Frequency': Start w/ 1 for '3-4 months', end at 3 for 'annual'\n",
    "- Locations of recurrence: {0: 'No', 3: 'Yes - Treated', 2: 'Yes - Not treated'} (*Note: 0-indexed bc null values can be imputed with 0. Not treated is highest value b/c it is 'worse'*)\n",
    "\n",
    "Consider:\n",
    "- 'Type of Resection': Only non-na values include 'minor' and 'major', could represent as 1 and 2 and all na as 0\n",
    "- 'Return of Bowel Function': Int values from 0 to >5 with no clear split. Not sure if making >5 = 6 is appropriate, keep categorical for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Extract staging features\n",
    "\n",
    "Place in hierarchy according to [ACS guidelines](https://www.cancer.org/cancer/types/colon-rectal-cancer/detection-diagnosis-staging/staged.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pre-Treatment T-Stage by MRI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pre-Treatment T-Stage by ERUS'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Drop leftover dirty samples\n",
    "- Dropped samples with the value 'â‰¥10-19 yearsNot applicable years' from Crohn's Disease\n",
    "- Dropped sample with the value '4' in Weight Loss\n",
    "- Dropped samples with Database ID 'UP0272' and 'VU025', date of diagnosis was not a fully formated date and was causing errors\n",
    "- Dropped the single '>0.44' value from Post-Treatment Tumor Diameter (cm)\n",
    "- Dropped two samples with value 'â‰¥3' from Number of Staple Fires to Transect Rectum\n",
    "- Dropped all samples with the value '4' in Tumor Differentiation\n",
    "- Dropped all samples prefixed with '>' or '<' from Proximal Margin Distance (cm), Distal Margin Distance (cm), and Radial Margin Distance (mm)\n",
    "- Dropped single '1' value from Type of Operation of Rectal Tumor\n",
    "- Dropped sample with Database ID 'UP0072', Anastonomic Leak diagnosis date was 7/11/01. Probably a typo for 2011, but better to drop just in case\n",
    "- Dropped 2 samples with the value '3' in Method of Leak Diagnosis\n",
    "- Dropped samples with values '1', '2', and '3' in Type of Intervention\n",
    "- Fixed encoding error in Time to Readmission and Time to Death, â‰¤ to <=\n",
    "- Dropped single sample with the value 'UnkNown' in Adjuvant Chemoradiation\n",
    "- Dropped samples with values of 1433.2 and 1436.1 in Recurrence Free Survival (Months)\n",
    "- Dropped samples with value '5' in 'Pre-Treatment Bladder Dysfunction'\n",
    "- Drop single sample with value 'Li Fraumeni' in 'Known Genetic Syndrome'\n",
    "- Drop single sample with value 'Complete small bowel obstruction' in 'Bowel Obstruction'\n",
    "- Drop sample with value '4' in 'Staging CT Chest'\n",
    "- Drop samples with values containing '>' or 'greater than' in any columns fitting '#... Lesions...' and 'Number... Nodes...' (*Note: Could also impute with mean in range*)\n",
    "- Drop 2 samples with value 'Proton therapy' in 'Radiation Technique'\n",
    "- Drop 1 sample with value '4' in 'Omental Flap to Pelvis'\n",
    "- Drop 1 sample with value '2' in 'Lesion Distribution' (*Note: Could be interpreted as 'bilobar'*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-summarize data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.violinplot(y=df.isnull().sum(), orient=\"v\", width=0.5)\n",
    "plot.set_title(\"Missing Values per Column\")\n",
    "plt.show()\n",
    "plot = sns.violinplot(y=[len(df[col].unique()) for col in df.select_dtypes(include=['object']).columns if \"Date\" not in col and col != \"Database ID\"], orient=\"v\", width=0.5)\n",
    "plot.set_title(\"Unique Values per Categorical Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = pd.DataFrame({\"Name\": df.columns.to_list(),\n",
    "                          \"dtype\": df.dtypes.to_list(),\n",
    "                          \"Num Non-Null\": df.count(axis=0).to_list(),\n",
    "                          \"Num Unique\": [len(df[col].unique()) for col in df.columns]})\n",
    "data_info.to_csv(\"../Data Documentation/cleaned_data_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clean dataframe dtypes\n",
    "Transforming months to days in step 5 caused a lot of errors that needed to be fixed since a few samples had strings instead of integers which led to issues when multiplying. This means that we need to go back through the csv and identify any columns that have values with dtypes that are not uniform accross all samples. This will help moving forward when we have to deal with outliers and imputation. This really should have been one of the first steps, but as we work through this we are modifying the main dataset so it will apply to all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decouple compounded features\n",
    "For example, a list of complications from a treatment. These should be split into multiple columns and one-hot encoded.\n",
    "### Columns to be parsed (a * indicates that the column is a duplicate name and needs to be renamed): \n",
    "- Complication During Neoadjuvant Treatment (Side Note: This should be categorical, 'Yes' values should be removed and Imputated with median or similar)\n",
    "- Type of Intraoperative Complication \n",
    "- Organs Invaded\n",
    "- Neoadjuvant Chemo Regimen (Side Note: This feature needs to be adaquitely cleaned, some of the values are not consistent or straightforward)\n",
    "- Adjuvant Chemo Regimen (Side Note: This feature needs to be adaquitely cleaned, some of the values are not consistent or straightforward)\n",
    "- Chemotherapy Regimen-Recurrence (Side Note: This feature needs to be adaquitely cleaned, some of the values are not consistent or straightforward) *\n",
    "### Processes\n",
    "With many unique values, binning/n-grams will need to be practiced to handle misspellings or other mistakes. This will be done by splitting each value into tokens and compliling a list of unique values to inspect and bin. Many of these features also have secondary columns that indicate whether or not the specific features are present. For example, a Chemotherapy field with yes or no values that correspond to the entries in the Chemotherapy Regimen-Recurrence column. These will need to be removed to avoid confusing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagnosis at readmission was discovered to need binning during dtype cleaning. Since binning is very time intensive with a dataset like this and the Nan count in the feature is 1358 after dtype cleaning pass 1, we will bin this iff it makes it past feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count = df['Diagnosis at Readmission'].isna().sum()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enumerator = 0\n",
    "unique_tokens = []\n",
    "for entry in therapy_complications:\n",
    "    if null_values.get(enumerator) == False:\n",
    "        if entry == 'No':\n",
    "            new_values.append('No')\n",
    "        elif entry == 'Yes':\n",
    "            new_values.append(\"Yes\")\n",
    "        else:\n",
    "            new_values.append('Yes')\n",
    "        entry = entry.replace(';', ',')\n",
    "        entry = entry.replace(', and', ',')\n",
    "        tokens = entry.split(', ')\n",
    "        trigger = False\n",
    "        for token in tokens:\n",
    "            token = token.lower()\n",
    "            for u in unique_tokens:\n",
    "                if token == u.lower():\n",
    "                    trigger = True\n",
    "            if (not trigger) and (token != 'no') and (token != 'yes') and (token != 'per notes'):\n",
    "                unique_tokens.append(token)\n",
    "            trigger = False\n",
    "    else:\n",
    "        new_values.append('No')\n",
    "    enumerator += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transform data\n",
    "Some data in this dataset needs to be transformed to fit the same scale as other, related features.\n",
    "### Columns to transform with units from/to in parenthesis (a * indicates that the column needs to be renamed): \n",
    "- Duration of Neoadjuvant Chemo-Days (Months/Days) *\n",
    "- Duration of Neoadjuvant ChemoXRT-Days (Months/Days) *\n",
    "- Adjuvant Chemo Duration-Days (Weeks/Days) *\n",
    "- Adjuvant Chemoradiation Duration-Days (Weeks/Days) *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#running this cell more than once WILL result in CORRUPTED VALUES, restart kernel before running\n",
    "\n",
    "months_to_days = ['Duration of Neoadjuvant Chemo-Days', 'Duration of Neoadjuvant ChemoXRT-Days']\n",
    "for feat in months_to_days:\n",
    "    df[feat] = df[feat].infer_objects()\n",
    "    df[feat] = df[feat].multiply(30)\n",
    "\n",
    "weeks_to_days = ['Adjuvant Chemo Duration-Days', 'Adjuvant Chemoradiation Duration-Days']\n",
    "for feat in weeks_to_days:\n",
    "    df[feat] = df[feat].infer_objects()\n",
    "    df[feat] = df[feat].multiply(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Drop single value columns\n",
    "Just like it sounds, these are columns that only contain a single value. These will only serve to distract our model since it cannot draw an inference from a static value, so we need to drop them from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from feature_selector import FeatureSelector\n",
    "fs = FeatureSelector(data = df)\n",
    "fs.identify_single_unique()\n",
    "print(fs.ops['single_unique'])\n",
    "fs.plot_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ops['single_unique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=fs.ops['single_unique'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Handling outliers\n",
    "In numeric columns, outliers can signifigantly impare the function of a model. However, it can also be beneficial for the model to see that a value is higher than average. \n",
    "### Brainstorming\n",
    "The first thing we need to do is filter out any non-numeric data, thanfully this will now be easy since we went through and cleaned out dtypes already. Ideally, I would like to create a folder containing data on each feature. I would like to use sklearn to find the 5-10 most related features and build graphs for each via seaborn's pairplot. Alternatively, we could simply create a large pairplot for each feature, acting as some form of a heat map.\n",
    "#### Given that the methods to adjust outliers vary in end result given their application (regression or classification), it may be worth exploring implementing outlier adjustments in the dynamic learning process. Ideally, the method of fixing outliers will change based on whether the data is currently being used for regression or classification. This could also be an opprotunity to implement Minkowski error\n",
    "### End Approach\n",
    "Having read a few whitepapers that indicate the most effective methods of outlier detection and adjustment vary by whether or not the application is regression or classification. Since the proposed archetecture contains both, it would be un-ideal to implement just one for the ground truth dataset. Therefore we will focus more on the second proposal in the brainstorming section, implementing outlier correction on the fly during training. However, we will be creating two pairplots of features so anyone outside of this use case can visualize distributions and outliers of this cleaned version of the dataset for their own application.\n",
    "#### Had to scrap pair grids, cell would not execute. Commented out code in case someone would like to borrow it\n",
    "### Proposed pairplots\n",
    "1. Box and Scatter plots \n",
    "2. Distribution and Bivariate kde plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box_scat = sns.PairGrid(df, dropna=True)\n",
    "#box_scat = box_scat.map_diag(sns.boxplot, color = \"o\", orient = \"v\")\n",
    "#box_scat = box_scat.map_offdiag(sns.scatter)\n",
    "#box_scat.savefig(\"grid_boxandscat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def hexabin(x, y):\n",
    "#    plt.hexbin(x, y, gridsize=50, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distr_hex = sns.PairGrid(df, dropna=True)\n",
    "#distr_hex = distr_hex.map_diag(sns.distplot, color = \"o\")\n",
    "#distr_hex = distr_hex.map_offdiag(hexabin)\n",
    "#istr_hex.savefig(\"grid_distrandhex.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Imputation\n",
    "This dataset is incredibly dirty and has a lot of missing values, this means we have to impute, or fill in, these missing values. However the method of which we do this depends quite heavily on the specific feature and the data within, this means the dataset has to be gone over by hand. \n",
    "### Process:\n",
    "The approach I will be taking here will be very similar to binning. The features will be split up into dictionaries to impute a defined default value, or a conditional value determined by a related feature. All remaining empty values will be filled by MICE, this is in lew of simply selecting the median or maximum occurred values from the column as such practices are less than ideal given they can be less accurate and even introduce bias into the data. MICE is done last since it works best with MAR data.\n",
    "### Default values for categorical cols:\n",
    "Typically a value such as 'None' would be imputed uniformly if a categorical column (with multiple categories, ie not simply yes and no) does not apply to a sample. However, this dataset uses many different NA values which means we need to locate these and replace them with a uniform alternative so these columns will be easier to work with when handling things like conditional logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcc-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
